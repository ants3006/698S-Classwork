{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping: IRNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain list of news from the coverpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url definition\n",
    "url = \"https://en.irna.ir/service/news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Request\n",
    "r1 = requests.get(url)\n",
    "r1.status_code\n",
    "\n",
    "# We'll save in coverpage the cover page content\n",
    "coverpage = r1.content\n",
    "\n",
    "# Soup creation\n",
    "soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "\n",
    "# News identification\n",
    "coverpage_news = soup1.find_all(class_='desc')\n",
    "len(coverpage_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list in which every element is a news article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"desc\">\n",
       "    <h3><a href=\"/news/83720519/Iranian-diplomat-urges-global-community-to-join-campaign-to-disregard\" target=\"_blank\" title=\"Yesterday 22:09\">Iranian diplomat urges global community to join campaign to disregard Iran sanctions</a>\n",
       "        \n",
       "    </h3>\n",
       "        <p>Tehran, March 18, IRNA â€“ Iran's ambassador in Tbilisi on Wednesday in a letter to the Georgian Prime Minister Giorgi Gakharia called on the international community to join the campaign to counter US unilateral and oppressive sanctions against Iran.  \n",
       "        </p>\n",
       "        <time><a href=\"/news/83720519/Iranian-diplomat-urges-global-community-to-join-campaign-to-disregard\">2020-03-18 22:09</a>\n",
       "        </time>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverpage_news[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's extract the text from the articles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll define the number of articles we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_articles = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists for content, links and titles\n",
    "news_contents = []\n",
    "list_links = []\n",
    "list_titles = []\n",
    "\n",
    "for n in np.arange(0, number_of_articles):\n",
    "        \n",
    "    # We need to ignore \"live\" pages since they are not articles\n",
    "    if \"live\" in coverpage_news[n].find('a')['href']:  \n",
    "        continue\n",
    "    \n",
    "    # Getting the link of the article\n",
    "    link = 'https://en.irna.ir' + coverpage_news[n].find('a')['href']\n",
    "    list_links.append(link)\n",
    "    \n",
    "    # Getting the title\n",
    "    title = coverpage_news[n].find('a').get_text()\n",
    "    list_titles.append(title)\n",
    "    \n",
    "    # Reading the content (it is divided in paragraphs)\n",
    "    article = requests.get(link)\n",
    "    article_content = article.content\n",
    "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "    body = soup_article.find_all('div', class_='item-body')\n",
    "    x = body[0].find_all('p')\n",
    "    \n",
    "    # Unifying the paragraphs\n",
    "    list_paragraphs = []\n",
    "    for p in np.arange(0, len(x)):\n",
    "        paragraph = x[p].get_text()\n",
    "        list_paragraphs.append(paragraph)\n",
    "        final_article = \" \".join(list_paragraphs)\n",
    "        \n",
    "    news_contents.append(final_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put them into:\n",
    "* a dataset which will the input of the models (`df_features`)\n",
    "* a dataset with the title and the link (`df_show_info`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features\n",
    "df_features = pd.DataFrame(\n",
    "     {'Article Content': news_contents \n",
    "    })\n",
    "\n",
    "# df_show_info\n",
    "df_show_info = pd.DataFrame(\n",
    "    {'Article Title': list_titles,\n",
    "     'Article Link': list_links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>In a statement on Wednesday, it claimed the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ghulam Sarwar Khan said this during a meeting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>According to Iran's Embassy to France, the car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"If we are to make the world that will emerge ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Referring to adverse impacts of inhumane and o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Article Content\n",
       "0  In a statement on Wednesday, it claimed the re...\n",
       "1  Ghulam Sarwar Khan said this during a meeting ...\n",
       "2  According to Iran's Embassy to France, the car...\n",
       "3  \"If we are to make the world that will emerge ...\n",
       "4  Referring to adverse impacts of inhumane and o..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article Title</th>\n",
       "      <th>Article Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>US imposes sanctions on Iranian nuclear scient...</td>\n",
       "      <td>https://en.irna.ir/news/83720594/US-imposes-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Pakistani aviation minister terms US anti-Iran...</td>\n",
       "      <td>https://en.irna.ir/news/83720578/Pakistani-avi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>France sends medical aid package to help Iran ...</td>\n",
       "      <td>https://en.irna.ir/news/83720567/France-sends-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Zarif calls for forging new path to emerge fro...</td>\n",
       "      <td>https://en.irna.ir/news/83720543/Zarif-calls-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Iranian diplomat urges global community to joi...</td>\n",
       "      <td>https://en.irna.ir/news/83720519/Iranian-diplo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Article Title  \\\n",
       "0  US imposes sanctions on Iranian nuclear scient...   \n",
       "1  Pakistani aviation minister terms US anti-Iran...   \n",
       "2  France sends medical aid package to help Iran ...   \n",
       "3  Zarif calls for forging new path to emerge fro...   \n",
       "4  Iranian diplomat urges global community to joi...   \n",
       "\n",
       "                                        Article Link  \n",
       "0  https://en.irna.ir/news/83720594/US-imposes-sa...  \n",
       "1  https://en.irna.ir/news/83720578/Pakistani-avi...  \n",
       "2  https://en.irna.ir/news/83720567/France-sends-...  \n",
       "3  https://en.irna.ir/news/83720543/Zarif-calls-f...  \n",
       "4  https://en.irna.ir/news/83720519/Iranian-diplo...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_show_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in how much time the script takes to get the news because this will impact directly on user experience. For this, we'll put it all into a single function and then call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_theguardian():\n",
    "    \n",
    "    # url definition\n",
    "    url = \"https://www.theguardian.com/uk\"\n",
    "    \n",
    "    # Request\n",
    "    r1 = requests.get(url)\n",
    "    r1.status_code\n",
    "\n",
    "    # We'll save in coverpage the cover page content\n",
    "    coverpage = r1.content\n",
    "\n",
    "    # Soup creation\n",
    "    soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
    "\n",
    "    # News identification\n",
    "    coverpage_news = soup1.find_all('h3', class_='fc-item__title')\n",
    "    len(coverpage_news)\n",
    "    \n",
    "    number_of_articles = 5\n",
    "\n",
    "    # Empty lists for content, links and titles\n",
    "    news_contents = []\n",
    "    list_links = []\n",
    "    list_titles = []\n",
    "\n",
    "    for n in np.arange(0, number_of_articles):\n",
    "\n",
    "        # We need to ignore \"live\" pages since they are not articles\n",
    "        if \"live\" in coverpage_news[n].find('a')['href']:  \n",
    "            continue\n",
    "\n",
    "        # Getting the link of the article\n",
    "        link = coverpage_news[n].find('a')['href']\n",
    "        list_links.append(link)\n",
    "\n",
    "        # Getting the title\n",
    "        title = coverpage_news[n].find('a').get_text()\n",
    "        list_titles.append(title)\n",
    "\n",
    "        # Reading the content (it is divided in paragraphs)\n",
    "        article = requests.get(link)\n",
    "        article_content = article.content\n",
    "        soup_article = BeautifulSoup(article_content, 'html5lib')\n",
    "        body = soup_article.find_all('div', class_='content__article-body from-content-api js-article__body')\n",
    "        x = body[0].find_all('p')\n",
    "\n",
    "        # Unifying the paragraphs\n",
    "        list_paragraphs = []\n",
    "        for p in np.arange(0, len(x)):\n",
    "            paragraph = x[p].get_text()\n",
    "            list_paragraphs.append(paragraph)\n",
    "            final_article = \" \".join(list_paragraphs)\n",
    "\n",
    "        news_contents.append(final_article)\n",
    "\n",
    "    # df_features\n",
    "    df_features = pd.DataFrame(\n",
    "         {'Content': news_contents \n",
    "        })\n",
    "\n",
    "    # df_show_info\n",
    "    df_show_info = pd.DataFrame(\n",
    "        {'Article Title': list_titles,\n",
    "         'Article Link': list_links,\n",
    "         'Newspaper': 'The Guardian'})\n",
    "\n",
    "    \n",
    "    return (df_features, df_show_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time elapsed is 1.905263 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "x, y = get_news_theguardian()\n",
    "end =time.time()\n",
    "te = end-start\n",
    "print(\"The time elapsed is %f seconds\" %(te))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
